cuda_visible_devices: "1"
device: gpu

dataset_name: "arXiv"
path_models: /scratch2/rldallitsako/HomoGraphs_AX/
file_to_save: MHAClassifier
logger_name: NoTemp_w30
logger_file: df_logger_cw.csv
num_executions: 5

load_data_paths:
  in_path: "/scratch2/rldallitsako/datasets/arXiv_classification/"
  data_train: ""
  labels_train: ""
  data_test: ""
  labels_test: ""
  with_val: True                  # True if validation set is available, False otherwise

model_arch_args:
  num_classes: 11
  lr: 0.001
  embed_dim: 384
  num_heads: 4
  dropout: 0.2
  hidden_dim : 128
  intermediate: True
  window: 30                              # set to 100 to run full self-attention, otherwise 1-99 according to % of document length
  # activation_attention: "relu"    # "relu" when using ReLU activation for attention, "sigmoid" for Sigmoid based-attention, and "anneal_decrease" for traditional Softmax attention adopting temperature annealing strategy.
  ### if the activation_attention is "relu" or "sigmoid", the following parameters are used:
  attn_dropout: 0.1
  ### if activation_attention is "anneal_decrease", the following parameters are used:
  temperature_scheduler : None #"anneal_decrease"
  # temperature_step: 0.0001
  # activation_attention: "softmax"


batch_size: 32
max_len: 1800
with_cw: True

trainer_args:
  max_epochs: 20
  enable_progress_bar: False

early_args:
  patience: 5
  min_delta: 0.001